{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athipan1/AI_Assistant_PaiNaiDee/blob/main/PaiNaiDee_Colab_Deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üáπüá≠ PaiNaiDee AI Assistant - Google Colab Deployment\n",
        "## ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡πÑ‡∏õ‡πÑ‡∏´‡∏ô‡∏î‡∏µ - ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ö‡∏ô Google Colab\n",
        "\n",
        "### ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ | Instructions:\n",
        "1. **‡∏£‡∏±‡∏ô‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏ó‡∏µ‡∏•‡∏∞‡πÄ‡∏ã‡∏•‡∏•‡πå** | Run cells one by one\n",
        "2. **‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à** | Wait for installation to complete  \n",
        "3. **‡πÉ‡∏™‡πà ngrok token** | Enter your ngrok token\n",
        "4. **‡∏Ñ‡∏•‡∏¥‡∏Å‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏ä‡πâ** | Click the link to access the app\n",
        "\n",
        "### ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå | Features:\n",
        "- ü§ñ 3D model visualization with AI\n",
        "- üé≠ Emotion analysis system  \n",
        "- üåç Tourism recommendations\n",
        "- üéÆ Interactive 3D viewer\n",
        "- üì± Multimodal action plans"
      ],
      "metadata": {
        "id": "title-section"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-dependencies"
      },
      "outputs": [],
      "source": [
        "# üîß ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies | Install Dependencies\n",
        "print(\"üîß Installing system dependencies...\")\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install -y gcc g++ cmake build-essential libgl1-mesa-glx libglib2.0-0 > /dev/null 2>&1\n",
        "\n",
        "print(\"üì¶ Installing Python packages...\")\n",
        "!pip install fastapi uvicorn python-multipart > /dev/null 2>&1\n",
        "!pip install transformers torch tokenizers accelerate scikit-learn joblib > /dev/null 2>&1\n",
        "!pip install opencv-python-headless mediapipe pillow sentencepiece > /dev/null 2>&1\n",
        "!pip install requests beautifulsoup4 wikipedia python-dotenv pydantic > /dev/null 2>&1\n",
        "!pip install langchain langchain-community > /dev/null 2>&1\n",
        "\n",
        "print(\"‚úÖ Dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå | Download Project\n",
        "import os\n",
        "import sys\n",
        "\n",
        "print(\"üì• Cloning PaiNaiDee AI Assistant repository...\")\n",
        "!git clone https://github.com/athipan1/AI_Assistant_PaiNaiDee.git > /dev/null 2>&1\n",
        "\n",
        "# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå | Change to project directory\n",
        "os.chdir('/content/AI_Assistant_PaiNaiDee/painaidee_ai_assistant')\n",
        "sys.path.append('/content/AI_Assistant_PaiNaiDee/painaidee_ai_assistant')\n",
        "\n",
        "print(\"‚úÖ Project downloaded successfully!\")\n",
        "print(f\"üìÅ Current directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "id": "download-project"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîë ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ngrok ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà token | Install ngrok and set token\n",
        "!pip install pyngrok > /dev/null 2>&1\n",
        "\n",
        "# ‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÉ‡∏™‡πà ngrok token ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà | IMPORTANT: Enter your ngrok token here\n",
        "# ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏ü‡∏£‡∏µ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà | Sign up for free at: https://ngrok.com/\n",
        "NGROK_TOKEN = \"\"  # ‚≠ê ‡πÉ‡∏™‡πà token ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ | Enter your token here\n",
        "\n",
        "if not NGROK_TOKEN:\n",
        "    print(\"‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà ngrok token ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ NGROK_TOKEN\")\n",
        "    print(\"‚ö†Ô∏è Please enter your ngrok token in the NGROK_TOKEN variable\")\n",
        "    print(\"üìù Get your free token at: https://ngrok.com/\")\n",
        "else:\n",
        "    from pyngrok import ngrok\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "    print(\"‚úÖ ngrok token set successfully!\")"
      ],
      "metadata": {
        "id": "setup-ngrok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå | Start Server\n",
        "import threading\n",
        "import time\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÉ‡∏ô‡πÄ‡∏ò‡∏£‡∏î‡πÅ‡∏¢‡∏Å | Create and start server in separate thread\n",
        "def start_server():\n",
        "    try:\n",
        "        from main import app\n",
        "        uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error starting server: {e}\")\n",
        "        # Fallback: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏á‡πà‡∏≤‡∏¢‡πÜ | Create simple server\n",
        "        from fastapi import FastAPI\n",
        "        simple_app = FastAPI(title=\"PaiNaiDee AI Assistant\")\n",
        "        \n",
        "        @simple_app.get(\"/\")\n",
        "        def read_root():\n",
        "            return {\n",
        "                \"message\": \"üáπüá≠ Welcome to PaiNaiDee AI Assistant!\", \n",
        "                \"status\": \"running\",\n",
        "                \"docs\": \"/docs\",\n",
        "                \"health\": \"/health\"\n",
        "            }\n",
        "        \n",
        "        @simple_app.get(\"/health\")\n",
        "        def health_check():\n",
        "            return {\"status\": \"healthy\", \"message\": \"PaiNaiDee AI Assistant is running\"}\n",
        "            \n",
        "        uvicorn.run(simple_app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÉ‡∏ô‡πÄ‡∏ò‡∏£‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á | Start server in background thread\n",
        "print(\"üöÄ Starting PaiNaiDee AI Assistant server...\")\n",
        "server_thread = threading.Thread(target=start_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô | Wait for server to start\n",
        "time.sleep(10)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á ngrok tunnel | Create ngrok tunnel\n",
        "print(\"üåê Creating ngrok tunnel...\")\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"‚úÖ Server is running!\")\n",
        "print(f\"üîó Public URL: {public_url}\")\n",
        "print(f\"üìö API Documentation: {public_url}/docs\")\n",
        "print(f\"üè• Health Check: {public_url}/health\")\n",
        "print(f\"üéÆ 3D Demo: {public_url}/static/demo.html\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üéâ PaiNaiDee AI Assistant is now live!\")\n",
        "print(\"üáπüá≠ ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡πÑ‡∏õ‡πÑ‡∏´‡∏ô‡∏î‡∏µ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß!\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "start-server"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö API | Test API\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Health Check\n",
        "try:\n",
        "    response = requests.get(f\"{public_url}/health\")\n",
        "    print(\"üè• Health Check:\")\n",
        "    print(json.dumps(response.json(), indent=2, ensure_ascii=False))\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Health check failed: {e}\")\n",
        "\n",
        "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö API ‡∏´‡∏•‡∏±‡∏Å (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)\n",
        "try:\n",
        "    test_data = {\"question\": \"Show me a walking person\"}\n",
        "    response = requests.post(f\"{public_url}/ai/select_model\", json=test_data)\n",
        "    if response.status_code == 200:\n",
        "        print(\"\\nü§ñ AI Model Selection Test:\")\n",
        "        print(json.dumps(response.json(), indent=2, ensure_ascii=False))\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è AI endpoint returned status: {response.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è AI test failed (this is normal if full features aren't loaded): {e}\")\n",
        "\n",
        "print(\"\\nüéØ ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô | Testing completed\")"
      ],
      "metadata": {
        "id": "test-api"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô | How to Use\n",
        "\n",
        "### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô | Usage Steps:\n",
        "\n",
        "1. **‡∏Ñ‡∏•‡∏¥‡∏Å‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô** | Click the links above to access:\n",
        "   - üîó **Public URL**: ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏´‡∏•‡∏±‡∏Å | Main website\n",
        "   - üìö **API Documentation**: ‡∏î‡∏π‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ API | View API docs\n",
        "   - üè• **Health Check**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ | Check server status\n",
        "   - üéÆ **3D Demo**: ‡∏ó‡∏î‡∏•‡∏≠‡∏á 3D viewer | Try 3D viewer\n",
        "\n",
        "2. **‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á** | Try commands:\n",
        "   - \"Show me a walking person\"\n",
        "   - \"‡∏´‡∏≤‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÉ‡∏Å‡∏•‡πâ‡∏â‡∏±‡∏ô\"\n",
        "   - \"I'm excited about my trip!\"\n",
        "\n",
        "3. **‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå** | Explore features:\n",
        "   - ü§ñ AI model selection\n",
        "   - üé≠ Emotion analysis  \n",
        "   - üåç Tourism recommendations\n",
        "   - üéÆ 3D visualization\n",
        "\n",
        "### üîß ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ | Troubleshooting:\n",
        "- ‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó Colab runtime | Restart Colab runtime\n",
        "- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ngrok token | Check ngrok token\n",
        "- ‡∏£‡∏±‡∏ô‡πÄ‡∏ã‡∏•‡∏•‡πå‡πÉ‡∏´‡∏°‡πà | Re-run cells\n",
        "\n",
        "### üí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö | Tips:\n",
        "- ‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏≤‡∏ö‡∏ó‡∏µ‡πà Colab ‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà | Server runs as long as Colab is open\n",
        "- URL ‡∏à‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó | URL changes every restart\n",
        "- ‡πÉ‡∏ä‡πâ GPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô | Use GPU for better performance"
      ],
      "metadata": {
        "id": "usage-instructions"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏ö‡∏ö | Show System Info\n",
        "import psutil\n",
        "import GPUtil\n",
        "\n",
        "print(\"üìä System Information:\")\n",
        "print(f\"üíæ RAM Usage: {psutil.virtual_memory().percent}%\")\n",
        "print(f\"üíΩ Disk Usage: {psutil.disk_usage('/').percent}%\")\n",
        "print(f\"üî• CPU Count: {psutil.cpu_count()}\")\n",
        "\n",
        "try:\n",
        "    gpus = GPUtil.getGPUs()\n",
        "    if gpus:\n",
        "        gpu = gpus[0]\n",
        "        print(f\"üéÆ GPU: {gpu.name}\")\n",
        "        print(f\"üéÆ GPU Memory: {gpu.memoryUsed}MB / {gpu.memoryTotal}MB\")\n",
        "    else:\n",
        "        print(\"üéÆ GPU: Not available\")\n",
        "except:\n",
        "    print(\"üéÆ GPU: Unable to detect\")\n",
        "\n",
        "print(\"\\nüîó Keep this Colab tab open to maintain the server\")\n",
        "print(\"üáπüá≠ ‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏ó‡πá‡∏ö Colab ‡∏ô‡∏µ‡πâ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ\")"
      ],
      "metadata": {
        "id": "system-info"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}